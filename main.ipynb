{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rimozione di artefatti in un dataset di mammografie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ribaltamento delle immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = pd.read_csv('data/Info.txt', sep=' ', index_col='REFNUM')\n",
    "\n",
    "for i in range(1, 323):\n",
    "    path = 'data/all-mias/mdb{:03d}.pgm'.format(i)\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if i % 2 != 0:\n",
    "        cv2.imwrite('data/ed/mdb{:03d}.png'.format(i), cv2.flip(img, 1))\n",
    "        #modifica nel dataset delle anomalie\n",
    "        x = anomalies.loc['mdb{:03d}'.format(i), 'X']\n",
    "        anomalies.loc['mdb{:03d}'.format(i), 'X'] = 1024-x\n",
    "    else:\n",
    "        cv2.imwrite('data/ed/mdb{:03d}.png'.format(i), img)\n",
    "\n",
    "anomalies.to_csv('data/text_removed/Info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rimozione del testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTexts(img):\n",
    "    #step 1: crop dell'immagine in una regione in cui è sicuramente\n",
    "    img_copy = np.copy(img)\n",
    "    crop = img_copy[0:400, 400:]\n",
    "\n",
    "    #step 2: applica  un filtro gaussiano per eliminare le basse frequenze\n",
    "    blurred_1 = cv2.GaussianBlur(crop, (63, 63), 0)\n",
    "    lpf = cv2.absdiff(crop, blurred_1)\n",
    "    \n",
    "    #step 3: Apertura per eliminare le piccole regioni bianche\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    cleaned = cv2.morphologyEx(lpf, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    #step 4: Canny\n",
    "    canny = cv2.Canny(cleaned, 20 , 50, apertureSize=3, L2gradient=True)\n",
    "    \n",
    "    #step 5: dilatazione per riempire i buchi\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilated = cv2.dilate(canny, kernel, iterations=2)\n",
    "\n",
    "    #step 6: si riempiono i contorni evidenziati da canny\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask_filled = np.zeros_like(canny)\n",
    "    cv2.drawContours(mask_filled, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    #step 7: si migliora il risultato costruendo l'involuco convesso\n",
    "    hull_list = [cv2.convexHull(cnt) for cnt in contours]\n",
    "    cv2.drawContours(mask_filled, hull_list, -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    #step 8: creazione della maschera ed apertura per eliminare i residui\n",
    "    mask = 255-mask_filled\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    #step 9: and logico con l'immagine di partenza\n",
    "    img_new = img_copy\n",
    "    img_new[0:400, 400:] = cv2.bitwise_and(crop, crop, mask=mask)\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcessing(edited, original):\n",
    "    canny = cv2.Canny(edited, 100 , 200, apertureSize=3, L2gradient=True)\n",
    "    canny = canny[0: 512, 320:]\n",
    "            \n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask_filled = np.zeros_like(canny)\n",
    "    cv2.drawContours(mask_filled, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    hull_list = [cv2.convexHull(cnt) for cnt in contours]\n",
    "    cv2.drawContours(mask_filled, hull_list, -1, 255, thickness=cv2.FILLED)        \n",
    "    \n",
    "    errors = canny + mask_filled\n",
    "    \n",
    "        \n",
    "    img_orig_crop = original[0:512, 320:] \n",
    "    img_crop = edited[0:512, 320:]\n",
    "\n",
    "    positions = np.where(errors != 0)\n",
    "    \n",
    "    for (k, t) in zip(positions[0], positions[1]):\n",
    "        if img_orig_crop[k][t] > 220 and t > 200:\n",
    "            img_crop[k][t] = 0\n",
    "        else:\n",
    "            img_crop[k][t] = img_orig_crop[k][t]\n",
    "            \n",
    "    return edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline di rimozione degli artefatti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = pd.read_csv('./data/corrette.txt')['1'].values\n",
    "sel = [i for i in range(1, 323) if i not in nums]\n",
    "\n",
    "#le cartelle devono essere create, perchè opencv non le crea automaticamente\n",
    "\n",
    "corrections = pd.read_csv('./data/correzioni.csv', index_col='img')\n",
    "\n",
    "for i in sel:\n",
    "    index = 'mdb{:03d}'.format(i)\n",
    "    path = 'data/ed/' + index +'.png'\n",
    "    original = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "    \n",
    "    needCorrections = index in corrections.index\n",
    "    \n",
    "    if (needCorrections) and corrections.loc[index]['type'] == 'b':\n",
    "        col = corrections.loc[index]['col']\n",
    "        original[:, col:] = 0\n",
    "        cv2.imwrite('data/text_removed/mdb{:03d}.png'.format(i), original)\n",
    "        \n",
    "    else:\n",
    "        edited = removeTexts(original)\n",
    "        edited = postProcessing(edited=edited, original=original)\n",
    "    \n",
    "        if needCorrections and corrections.loc[index]['type'] == 'a':\n",
    "            col = corrections.loc[index]['col']\n",
    "            edited[:, col:] = 0\n",
    "            \n",
    "        cv2.imwrite('data/text_removed/mdb{:03d}.png'.format(i), edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casi particolari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casi particolari\n",
    "path = 'data/ed/mdb274.png'\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "ed = postProcessing(edited=removeTexts(img), original=img)\n",
    "ed[920:, :] = 0\n",
    "ed[:, 750:] =0\n",
    "cv2.imwrite('data/text_removed/mdb274.png', ed)\n",
    "\n",
    "path = 'data/ed/mdb280.png'\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "ed = postProcessing(edited=removeTexts(img), original=img)\n",
    "ed[900:, :] = 0\n",
    "ed[:, 750:] =0\n",
    "cv2.imwrite('data/text_removed/mdb280.png', ed)\n",
    "\n",
    "path = 'data/ed/mdb308.png'\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "img[0:250, 700:] = 0\n",
    "cv2.imwrite('data/text_removed/mdb308.png', ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rimozioni di piccole strisce bianche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = pd.read_csv('./data/corrette.txt')['1'].values\n",
    "sel = [i for i in range(1, 323) if i not in nums]\n",
    "\n",
    "no_strip = [32, 50, 126, 133, 134, 141, 144, 173, 193, 216, 260, 279, 294, 300, 310, 320]\n",
    "\n",
    "for i in no_strip:\n",
    "    sel.remove(i)\n",
    "    \n",
    "for i in sel:\n",
    "    path = 'data/text_removed/mdb{:03d}.png'.format(i)\n",
    "    original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    crop = original[0:400, 700:]\n",
    "    \n",
    "    contrast = cv2.convertScaleAbs(src=crop, alpha=1, beta=100)\n",
    "    _, ret = cv2.threshold(contrast, 170 ,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    open = cv2.morphologyEx(ret, cv2.MORPH_OPEN, kernel=cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(33, 33)))\n",
    "    mask = 255 - cv2.subtract(ret, open)\n",
    "    \n",
    "    pos = np.where(mask == 0)\n",
    "\n",
    "    crop[pos[0], pos[1]] = 0\n",
    "    cv2.imwrite('data/text_removed/mdb{:03d}.png'.format(i), original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
